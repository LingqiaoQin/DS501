{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "** Due Date: February 10, before the class**\n",
    "\n",
    "*------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:**\n",
    "    \n",
    "    Haley Huang\n",
    "    Helen Hong\n",
    "    Tom Meagher\n",
    "    Tyler Reese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "# API CONSTANTS\n",
    "CONSUMER_KEY = '92TpJf8O0c9AWN3ZJjcN8cYxs'\n",
    "CONSUMER_SECRET ='dyeCqzI2w7apETbTUvPai1oCDL5oponvZhHSmYm5XZTQbeiygq'\n",
    "OAUTH_TOKEN = '106590533-SEB5EGGoyJ8EsjOKN05YuOQYu2rg5muZgMDoNrqN'\n",
    "OAUTH_TOKEN_SECRET = 'BficAky6uGyGfRzDGJqZYVKo0HS6G6Ex3ijYW3zy3kjNJ'\n",
    "    \n",
    "def oauth_login(token, token_secret, consumer_key, consumer_secret):\n",
    "    \"\"\"\n",
    "    Snag an auth from Twitter\n",
    "    \"\"\"\n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    return auth\n",
    "\n",
    "def save_json(filename, data):\n",
    "    \"\"\"\n",
    "    Save json data to a filename\n",
    "    \"\"\"\n",
    "    print 'Saving data into {0}.json...'.format(filename)\n",
    "    with io.open('{0}.json'.format(filename), \n",
    "                 'w', encoding='utf-8') as f:\n",
    "        f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
    "\n",
    "def load_json(filename):\n",
    "    \"\"\"\n",
    "    Load json data from a filename\n",
    "    \"\"\"\n",
    "    print 'Loading data from {0}.json...'.format(filename)\n",
    "    with open('{0}.json'.format(filename)) as f:    \n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bingo! API and stream set up!\n"
     ]
    }
   ],
   "source": [
    "# Create an api and stream instance\n",
    "auth = oauth_login(CONSUMER_KEY, CONSUMER_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "twitter_stream = twitter.TwitterStream(auth=auth)\n",
    "if twitter_api and twitter_stream:\n",
    "    print 'Bingo! API and stream set up!'\n",
    "else:\n",
    "    print 'Hmmmm, something is wrong here.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TwitterHTTPError",
     "evalue": "Twitter sent status 420 for URL: 1.1/statuses/filter.json using parameters: (oauth_consumer_key=92TpJf8O0c9AWN3ZJjcN8cYxs&oauth_nonce=1478908005266195875&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1454714036&oauth_token=106590533-SEB5EGGoyJ8EsjOKN05YuOQYu2rg5muZgMDoNrqN&oauth_version=1.0&track=Patriots&oauth_signature=poWvbBWKAmw%2BTa%2BxWcAqliCJzJk%3D)\ndetails: Exceeded connection limit for user\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTwitterHTTPError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-44fe4e6030cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Collect Patriots tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Patriots\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpatriots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'tweets'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\twitter\\api.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response_with_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\twitter\\stream.pyc\u001b[0m in \u001b[0;36m_handle_response\u001b[1;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[0;32m    282\u001b[0m                 return handle_stream_response(\n\u001b[0;32m    283\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m                     _timeout or timeout, heartbeat_timeout)\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         TwitterCall.__init__(\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\twitter\\stream.pyc\u001b[0m in \u001b[0;36mhandle_stream_response\u001b[1;34m(req, uri, arg_data, block, timeout, heartbeat_timeout)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib_request\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0murllib_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTwitterJSONIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheartbeat_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTwitterHTTPError\u001b[0m: Twitter sent status 420 for URL: 1.1/statuses/filter.json using parameters: (oauth_consumer_key=92TpJf8O0c9AWN3ZJjcN8cYxs&oauth_nonce=1478908005266195875&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1454714036&oauth_token=106590533-SEB5EGGoyJ8EsjOKN05YuOQYu2rg5muZgMDoNrqN&oauth_version=1.0&track=Patriots&oauth_signature=poWvbBWKAmw%2BTa%2BxWcAqliCJzJk%3D)\ndetails: Exceeded connection limit for user\r\n"
     ]
    }
   ],
   "source": [
    "# Collect Patriots tweets\n",
    "track = \"Patriots\"\n",
    "stream = twitter_stream.statuses.filter(track=track)\n",
    "\n",
    "patriots = {'tweets': []}\n",
    "for tweet in stream:\n",
    "    if len(patriots['tweets']) > 10:\n",
    "        break\n",
    "    else:\n",
    "        patriots['tweets'].append(tweet)\n",
    "\n",
    "twit_stream = stream\n",
    "print twit_stream\n",
    "# Save tweets to file\n",
    "filename = \"patriots\"\n",
    "save_json(filename, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this code to load tweets that have already been collected\n",
    "\n",
    "filename = \"patriots\"\n",
    "results = load_json(filename)\n",
    "print \"Loading tweets into results variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute Additional Statistics about the tweets collected\n",
    "\n",
    "# Determine the average number of words in the text of each tweet\n",
    "def average_words(tweet_texts):\n",
    "    total_words =  sum([len(s.split()) for s in tweet_texts])\n",
    "    return 1.0*total_words/len(tweet_texts)\n",
    "\n",
    "tweet_texts = [ tweet['text'] \n",
    "                 for tweet in results ]\n",
    "\n",
    "print 'Average number of words:', average_words(tweet_texts)\n",
    "\n",
    "# Calculate the lexical diversity of all words contained in the tweets\n",
    "def lexical_diversity(tokens):\n",
    "    return 1.0*len(set(tokens))/len(tokens)\n",
    "\n",
    "words = [ word \n",
    "          for tweet in tweet_texts \n",
    "              for word in tweet.split() ]\n",
    "\n",
    "print 'Lexical Diversity:', lexical_diversity(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: jack\n",
    "\n",
    "* The total number of tweets collected:  19\n",
    "\n",
    "* Average number of words per tweet: 13.9\n",
    "\n",
    "* Lexical Diversity of all words contained in the collection of tweets: 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "import nltk\n",
    "\n",
    "tweet_texts = [ tweet['text'] \n",
    "                 for tweet in results ]\n",
    "words = [ word \n",
    "          for tweet in tweet_texts \n",
    "              for word in tweet.split()\n",
    "                 if word not in ['RT'] # filter out RT as stop word\n",
    "        ]\n",
    "\n",
    "# Use the natural language toolkit to eliminate stop words\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "non_stop_words = [w for w in words if w not in stop_words]\n",
    "\n",
    "# frequency of words\n",
    "count = Counter(non_stop_words).most_common()\n",
    "\n",
    "# table of the top 30 words with their counts\n",
    "pretty_table = PrettyTable(field_names=['Word', 'Count']) \n",
    "[ pretty_table.add_row(w) for w in count[:30] ]\n",
    "pretty_table.align['Word'] = 'l'\n",
    "pretty_table.align['Count'] = 'r'\n",
    "print pretty_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Create a list of all tweets with at least one retweet, and index the originator of that tweet and the text.\n",
    "retweets = [\n",
    "            (tweet['retweet_count'],\n",
    "            tweet['retweeted_status']['user']['screen_name'],\n",
    "            tweet['text'])\n",
    "            \n",
    "            #Ensure that a retweet exists\n",
    "            for tweet in results                      \n",
    "                if tweet.has_key('retweeted_status')\n",
    "            ]\n",
    "\n",
    "pretty_table = PrettyTable(field_names = ['Count','Screen Name','Text'])\n",
    "\n",
    "# Sort tweets by descending number of retweets and display the top 10 results in a table.\n",
    "[pretty_table.add_row(row) for row in sorted(retweets, reverse = True)[:10]]\n",
    "pretty_table.max_width['Text'] = 50\n",
    "pretty_table.align = 'l'\n",
    "print pretty_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another measure of tweet \"popularity\" could be the number of times it is favorited.  The following calculates the top-10 tweets with the most \"favorites\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Determine the number of \"favorites\" for each tweet collected.\n",
    "\n",
    "favorites = [\n",
    "            (tweet['favorite_count'],\n",
    "             tweet['text'])\n",
    "            for tweet in results\n",
    "            ]\n",
    "            \n",
    "pretty_table = PrettyTable(field_names = ['Count','Text'])\n",
    "\n",
    "# Sort tweets by descending number of favorites and display the top 10 results in a table.\n",
    "[pretty_table.add_row(row) for row in sorted(favorites, reverse = True)[:10]]\n",
    "pretty_table.max_width['Text'] = 75\n",
    "pretty_table.align = 'l'\n",
    "print pretty_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Extract the screen names which appear among the collection of tweets\n",
    "screen_names = [user_mention['screen_name']\n",
    "               for tweet in results\n",
    "                   for user_mention in tweet['entities']['user_mentions']]\n",
    "\n",
    "# Extract the hashtags which appear among the collection of tweets\n",
    "hashtags = [ hashtag['text']\n",
    "           for tweet in results\n",
    "               for hashtag in tweet['entities']['hashtags']]\n",
    "\n",
    "# Simultaneously determine the frequency of screen names/hashtags, and display the top 10 most common in a table.\n",
    "for label, data in (('Screen Name',screen_names),\n",
    "                   ('Hashtag',hashtags)):\n",
    "    pretty_table = PrettyTable(field_names =[label,'Count'])\n",
    "    counter = Counter(data)\n",
    "    [ pretty_table.add_row(entity) for entity in counter.most_common()[:10]]\n",
    "    pretty_table.align[label] ='l'\n",
    "    pretty_table.align['Count'] = 'r'\n",
    "    print pretty_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "#Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "import sys\n",
    "import time\n",
    "from urllib2 import URLError\n",
    "from httplib import BadStatusLine\n",
    "import json\n",
    "from functools import partial\n",
    "from sys import maxint\n",
    "\n",
    "# The following is the \"general-purpose API wrapper\" presented in \"Mining the Social Web\" for making robust twitter requests.\n",
    "# This function can be used to accompany any twitter API function.  It force-breaks after receiving more than max_errors\n",
    "# error messages from the Twitter API.\n",
    "def make_twitter_request(twitter_api_func, max_errors = 10, *args, **kw):\n",
    "    def handle_twitter_http_error(e, wait_period = 2, sleep_when_rate_limited = True):\n",
    "        \n",
    "        if wait_period > 3600:\n",
    "            print >> sys.stderr, 'Too many retries. Quitting.'\n",
    "            raise e\n",
    "        \n",
    "        if e.e.code == 401:\n",
    "            print >> sys.stderr, 'Encountered 401 Error (Not Authorized)'\n",
    "            return None\n",
    "        \n",
    "        elif e.e.code == 404:\n",
    "            print >> sys.stderr, 'Encountered 404 Error (Not Found)'\n",
    "            return None\n",
    "        \n",
    "        elif e.e.code == 429:\n",
    "            print >> sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)'\n",
    "            if sleep_when_rate_limited:\n",
    "                print >> sys.stderr, \"Retrying again in 15 Minutes...ZzZ...\"\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print >> sys.stderr, '...ZzZ...Awake now and trying again.'\n",
    "                return 2\n",
    "            else:\n",
    "                raise e\n",
    "                \n",
    "        elif e.e.code in (500,502,503,504):\n",
    "            print >> sys.stderr, 'Encountered %i Error.  Retrying in %i seconds' % \\\n",
    "                (e.e.code, wait_period)\n",
    "            time.sleel(wait.period)\n",
    "            wait.period *= 1.5\n",
    "            return wait_period\n",
    "        \n",
    "        else:\n",
    "            raise e\n",
    "            \n",
    "    wait_period = 2\n",
    "    error_count = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args,**kw)\n",
    "        except twitter.api.TwitterHTTPError, e:\n",
    "            error_count = 0\n",
    "            wait_period = handle_twitter_http_error (e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "            \n",
    "        except URLError, e:\n",
    "            error_count += 1\n",
    "            print >> sys.stderr, \"URLError encountered.  Continuing\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise\n",
    "        \n",
    "        except BadStatusLine, e:\n",
    "            error_count += 1\n",
    "            print >> sys.stderr, \"BadStatusLineEncountered.  Continuing\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function uses the above Robust Request wrapper to retreive all friends and followers of a given user.  This code\n",
    "# can be found in Chapter 9, the `Twitter Cookbook' in \"Mining the social web\"\n",
    "\n",
    "from functools import partial\n",
    "from sys import maxint\n",
    "\n",
    "def get_friends_followers_ids(twitter_api, screen_name = None, user_id = None, friends_limit = maxint, followers_limit = maxint):\n",
    "    assert(screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/friends/ids and\n",
    "    # https://dev.twitter.com/docs/api/1.1/get/followers/ids for details\n",
    "    # on API parameters\n",
    "    \n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, \n",
    "                              count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids, \n",
    "                                count=5000)\n",
    "\n",
    "    friends_ids, followers_ids = [], []\n",
    "    \n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"], \n",
    "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "                ]:\n",
    "        \n",
    "        if limit == 0: continue\n",
    "        \n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "        \n",
    "            # Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name: \n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "        \n",
    "            print 'Fetched {0} total {1} ids for {2}'.format(len(ids), \n",
    "                                                    label, (user_id or screen_name))\n",
    "        \n",
    "            # XXX: You may want to store data during each iteration to provide an \n",
    "            # an additional layer of protection from exceptional circumstances\n",
    "        \n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "                \n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the friends and followers of a user and save to a json file.\n",
    "\n",
    "screen_name = 'RobGronkowski'\n",
    "\n",
    "gronk_friends_ids, gronk_followers_ids = get_friends_followers_ids(twitter_api, screen_name = screen_name)\n",
    "\n",
    "filename = \"gronk_friends\"\n",
    "print 'Saving tweets into {0}.json'.format(filename)\n",
    "save_json(filename, gronk_friends_ids)\n",
    "\n",
    "filename = \"gronk_followers\"\n",
    "print 'Saving tweets into {0}.json'.format(filename)\n",
    "save_json(filename, gronk_followers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following function retrieves the screen names of Twitter users, given their user IDs.  If a certain number of screen\n",
    "# names is desired (for example, 20) max_ids limits the number retreived.\n",
    "\n",
    "def get_screen_names(twitter_api, user_ids = None, max_ids = None):\n",
    "\n",
    "    response = []\n",
    "    \n",
    "    items = user_ids\n",
    "    \n",
    "    # Due to individual user security settings, not all user profiles can be obtained.  Iterate over all user IDs\n",
    "    # to ensure at least (max_ids) screen names are obtained.\n",
    "    \n",
    "    while len(response) < max_ids:\n",
    "        items_str = ','.join([str(item) for item in items[:100]])\n",
    "        items = items[100:]\n",
    "        \n",
    "        responses = make_twitter_request(twitter_api.users.lookup, user_id = items_str)\n",
    "        \n",
    "        response += responses\n",
    "    \n",
    "    items_to_info = {}\n",
    "     \n",
    "    # The above loop has retrieved all user information.    \n",
    "    for user_info in response:\n",
    "        items_to_info[user_info['id']] = user_info\n",
    "    \n",
    "    # Extract only the screen names obtained.  The keys of items_to_info are the user ID numbers.\n",
    "    names = [items_to_info[number]['screen_name']\n",
    "            for number in items_to_info.keys()\n",
    "            ]\n",
    "\n",
    "    numbers =[number for number in items_to_info.keys()]\n",
    "\n",
    "    return names , numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Given a set of user ids, this function calls get_screen_names and plots a table of the first (max_ids) ID's and screen names.\n",
    "def table_ids_screen_names(twitter_api, user_ids = None, max_ids = None):\n",
    "\n",
    "    names, numbers = get_screen_names(twitter_api, user_ids = user_ids, max_ids = max_ids)\n",
    "\n",
    "    ids_screen_names = zip(numbers, names)\n",
    "    \n",
    "    pt = PrettyTable(field_names = ['User ID','Screen Name'])\n",
    "    [ pt.add_row (row) for row in ids_screen_names[:max_ids]]\n",
    "    pt.align = 'l'\n",
    "    print pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a list of friends_ids and followers_ids, this function counts and prints the size of each collection.\n",
    "# It then plots a tables of the first (max_ids) listed friends and followers.\n",
    "def display_friends_followers(screen_name, friends_ids, followers_ids ,max_ids = None):\n",
    "    friends_ids_set, followers_ids_set = set(friends_ids),set(followers_ids)\n",
    "    \n",
    "    print\n",
    "    print '{0} has {1} friends.  Here are {2}:'.format(screen_name, len(friends_ids_set),max_ids)\n",
    "    print\n",
    "    table_ids_screen_names(twitter_api, user_ids = friends_ids, max_ids = max_ids)\n",
    "    print\n",
    "    print '{0} has {1} followers.  Here are {2}:'.format(screen_name,len(followers_ids_set),max_ids)\n",
    "    print\n",
    "    table_ids_screen_names(twitter_api, user_ids = followers_ids, max_ids = max_ids)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_friends_followers(screen_name = screen_name, friends_ids = gronk_friends_ids, followers_ids = gronk_followers_ids, max_ids = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a list of friends_ids and followers_ids, this function use set intersection to find the number of mutual friends.\n",
    "# It then plots a table of the first (max_ids) listed mutual friends.\n",
    "\n",
    "def display_mutual_friends(screen_name, friends_ids, followers_ids ,max_ids = None):\n",
    "    friends_ids_set, followers_ids_set = set(friends_ids),set(followers_ids)\n",
    "    \n",
    "    print\n",
    "    print '{0} has {1} mutual friends.  Here are {2}:'.format(screen_name, len(friends_ids_set.intersection(followers_ids_set)),max_ids)\n",
    "    print\n",
    "    mutual_friends_ids = list(friends_ids_set.intersection(followers_ids_set))\n",
    "    table_ids_screen_names(twitter_api, user_ids = mutual_friends_ids, max_ids = max_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_mutual_friends(screen_name = screen_name, friends_ids = gronk_friends_ids, followers_ids = gronk_followers_ids, max_ids = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "#Problem 4: Explore the data \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through myWPI, in the Assignment \"Case Study 1\".\n",
    "        \n",
    "** Note: Each team just need to submit one submission in myWPI **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Explore the data\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
